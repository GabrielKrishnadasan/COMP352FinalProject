{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm, skew, probplot\n",
    "from scipy.special import boxcox1p\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas.*\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file and see number of rows and cols\n",
    "nba_df = pd.read_csv(\"nba_2022-23_all_stats_with_salary.csv\")\n",
    "nba_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reanme 'Unnamed: 0' column to 'ID'\n",
    "nba_df = nba_df.rename(columns={\"Unnamed: 0\": \"Id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces from column names\n",
    "nba_df.columns = [col.replace(\" \", \"\") for col in nba_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of categorical variables\n",
    "category_count = 0\n",
    "\n",
    "for cat in nba_df.dtypes:\n",
    "    if cat == \"object\":\n",
    "        category_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of categorical variables:\", category_count)\n",
    "\n",
    "# column 1 is the ID column so we subract 1\n",
    "numeric_count = nba_df.shape[1] - category_count - 1\n",
    "\n",
    "print(\"Number of contineous variables:\", numeric_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all the column names\n",
    "nba_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling our missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the missing data and its percent of the column\n",
    "total_missing = nba_df.isnull().sum().sort_values(ascending=False)\n",
    "percent_missing = (nba_df.isnull().sum() / nba_df.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "missing_data_df = pd.concat([total_missing, percent_missing], axis=1, keys=[\"Total Missing\", \"Percent Missing\"])\n",
    "missing_data_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example row of a player who has missing data\n",
    "# players with missing data are those who did not play many games so they never accumilated that stat during the season\n",
    "null_fg = nba_df[nba_df['FG%'].isnull()]\n",
    "null_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize this in a bar graph\n",
    "missing_data_df[\"Percent Missing\"].head(8).plot(\n",
    "    kind=\"barh\", figsize=(20,10)\n",
    ").invert_yaxis()\n",
    "plt.xlabel(\"Percent Missing\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.title(\"The 8 Columns and their Percent of Missing Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the missing data with 0s\n",
    "# data is \"missing\" because player never recorded that stat during the season so we impute that data to be 0 to identify them in our model\n",
    "cols_to_fill_zero = [\n",
    "    \"FT%\",\n",
    "    \"3P%\",\n",
    "    \"2P%\",\n",
    "    \"TS%\",\n",
    "    \"3PAr\",\n",
    "    \"FTr\",\n",
    "    \"eFG%\",\n",
    "    \"FG%\",\n",
    "]\n",
    "\n",
    "for col in cols_to_fill_zero:\n",
    "    nba_df[col] = nba_df[col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show same player who had null values now has zeros in those fields\n",
    "imputed_row = nba_df[nba_df[\"PlayerName\"] == \"Alondes Williams\"]\n",
    "imputed_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers for better training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates multiple plots to see if there are any outliers in salary\n",
    "sns.set()\n",
    "\n",
    "cols = [\n",
    "    'Age',\n",
    "    'MP',\n",
    "    'PTS', \n",
    "    'DWS', \n",
    "    'VORP'\n",
    "]\n",
    "\n",
    "target = 'Salary'\n",
    "\n",
    "fig, axes = plt.subplots(1, len(cols), figsize=(25, 6))\n",
    "\n",
    "# loop through the features and create a scatter plot for each\n",
    "for i, feature in enumerate(cols):\n",
    "    sns.scatterplot(data=nba_df, x=feature, y=target, ax=axes[i])\n",
    "    axes[i].set_title(f'Salary vs. {feature}')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Salary (Tens of Millions)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(nba_df[\"Salary\"], fit=norm)\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(nba_df[\"Salary\"])\n",
    "print(\"\\n mu = {:.2f} and sigma = {:.2f}\\n\".format(mu, sigma))\n",
    "\n",
    "# Now plot the distribution\n",
    "plt.legend(\n",
    "    [\"Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )\".format(mu, sigma)], loc=\"best\"\n",
    ")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Salary distribution\")\n",
    "\n",
    "# Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = probplot(nba_df[\"Salary\"], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "nba_df[\"Salary_normalized\"] = np.log1p(nba_df[\"Salary\"])\n",
    "\n",
    "# Check the new distribution\n",
    "sns.distplot(nba_df[\"Salary_normalized\"], fit=norm)\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(nba_df[\"Salary_normalized\"])\n",
    "print(\"\\n mu = {:.2f} and sigma = {:.2f}\\n\".format(mu, sigma))\n",
    "\n",
    "# Now plot the distribution\n",
    "plt.legend(\n",
    "    [\"Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )\".format(mu, sigma)], loc=\"best\"\n",
    ")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Salary distribution\")\n",
    "\n",
    "# Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = probplot(nba_df[\"Salary_normalized\"], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot\n",
    "sns.set()\n",
    "cols = [\n",
    "    \"Salary_normalized\",\n",
    "    \"Age\",\n",
    "    \"MP\",\n",
    "    \"3P\",\n",
    "    \"TRB\",\n",
    "    \"AST\",\n",
    "    \"PTS\",\n",
    "    \"PER\",\n",
    "    \"TS%\",\n",
    "    \"DWS\",\n",
    "    \"VORP\"\n",
    "]\n",
    "sns.pairplot(nba_df[cols], size=2.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude non-numeric columns\n",
    "numeric_df = nba_df.select_dtypes(include=[np.number])\n",
    "corrmat = numeric_df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "sns.heatmap(corrmat, vmax=0.8, square=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_correlations = corrmat['Salary']\n",
    "print(salary_correlations.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analytics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ccb5ea80edbfae8c6780fa0b5909321291a27faa1189b515049edc570dffb73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
